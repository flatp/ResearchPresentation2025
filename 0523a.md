---
layout: page
title: 5月23日
---

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

## 5.1 正規モデル

### 正規分布とは

$$
\begin{align}
f(y \mid \theta , \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}(\frac{y - \theta}{\sigma})^2}
\end{align}
$$

ただし$\theta$は平均、$\sigma^2$は分散

- 分布は$\theta$に関して対称
    - 平均 = 中央値 = 最頻値 = $\theta$
- 分布の約95%は平均から標準誤差の2倍の距離の間にある
- $X \sim \mathcal{N} ( \mu,\tau^2 )$かつ$Y \sim \mathcal{N} ( \theta,\sigma^2 )$ならば$aX + bY \sim \mathcal{N} ( a\mu + b\theta,\; a^2\tau^2 + b^2\sigma^2)$
- Rのコマンドは$\sigma^2$ではなく$\sigma$を引数にとる

### 中心極限定理
非常に一般的な状況のもとで、確率変数の和は近似的に正規分布に従う

⟹ 多くの要素を足してできるものから生じるデータに対して、正規分布に基づく標本モデルは適切


## 5.2 分散所与の下での平均に関する推測

### 十分統計量

$\{Y_1, \ldots, Y_n \mid \theta, \sigma^2 \} \sim \mathrm{i.i.d.} \mathcal{N} ( \theta,\sigma )$を考える

$$
\begin{align*}
p(y_1, \ldots , y_n \mid \theta, \sigma^2) &= \prod_{i=1}^{n} p(y_i \mid \theta, \sigma^2)\\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}(\frac{y - \theta}{\sigma})^2} \\
&= (2\pi\sigma^2)^{-\frac{n}{2}}\exp\left\{-\frac{n}{2}\sum\left(\frac{y_i - \theta}{\sigma}\right)^2\right\}
\end{align*}
$$

指数の中にある二次の項を展開して

$$
\begin{align*}
\sum_{i = 1}^{n}\left(\frac{y_i - \theta}{\sigma}\right)^2 = \frac{1}{\sigma^2}\sum y_i^2 - 2 \frac{\theta}{\sigma^2}\sum y_i + n\frac{\theta^2}{\sigma^2}
\end{align*}
$$

以上より$\{\sum y_i^2, \sum y_i \}$は二次元の十分統計量

すなわち$\{\bar{y}, s^2 \}$も十分統計量

### $\sigma^2$が既知の場合の$\theta$の推測に関する問題

事後分布は

$$
\begin{align*}
 p(\theta\mid y_1, \ldots , y_n,\sigma^2) &\propto p(\theta\mid\sigma^2)\times e^{-\frac{1}{2\sigma^2}\sum(y_i-\theta)}\\
 &\propto p(\theta\mid\sigma^2)\times e^{c_1(\theta - c_2)^2}
\end{align*}
$$

- $p(\theta\mid\sigma^2)$が共役になるために、$e^{c_1(\theta - c_2)^2}$のような二次の項が必要
- そのような$\mathbb{R}$上の確率分布のクラスでもっとも単純なものは正規分布

⟹ $p(\theta\mid\sigma^2)$が正規分布かつ$y_1,\ldots,yn$が独立に同一の$\mathcal{N} ( \theta,\sigma^2 )$に従うならば、$p(\theta\mid y_1, \ldots , y_n,\sigma^2)$も正規分布になる

この主張を確かめる

$\theta\sim\mathcal{N} ( \mu_0,\tau_0^2 )$のとき

$$
\begin{align*}
 p(\theta\mid y_1, \ldots , y_n,\sigma^2) &= \frac{p(\theta\mid\sigma^2)p(y_1, \ldots , y_n \mid \theta, \sigma^2)}{p(y_1, \ldots , y_n \mid \sigma^2)}\\
 &\propto p(\theta\mid\sigma^2)p(y_1, \ldots , y_n \mid \theta, \sigma^2)\\
 &\propto \exp\left\{-\frac{1}{2\tau_0^2}(\theta-\mu_0)^2\right\}\exp\left\{-\frac{1}{2\sigma^2}\sum(y_i-\theta)^2\right\}
\end{align*}
$$

定数を無視して指数の中の和を計算

$$
\begin{align*}
\frac{1}{\tau_0^2}(\theta^2-2\theta\mu_0+\mu_0^2)+\frac{1}{\sigma^2}(\sum y_i^2 - 2\theta\sum y_i + n\theta^2) = a\theta^2-2b\theta+c,\\
a=\frac{1}{\tau_0^2}+\frac{n}{\sigma^2},\; b=\frac{\mu_0}{\tau_0^2}+\frac{\sum y_i}{\sigma^2},\; c=c(\mu_0,\tau_0^2,\sigma^2,y_1,\ldots,y_n)
\end{align*}
$$

これを代入して

$$
\begin{align*}
 p(\theta\mid y_1, \ldots , y_n,\sigma^2) &\propto \exp\left\{-\frac{1}{2}(a\theta^2-2b\theta)\right\}\\
 &= \exp\left\{-\frac{1}{2}a(\theta^2-\frac{2b\theta}{a}+\frac{b^2}{a^2})+\frac{b^2}{2a}\right\}\\
 &\propto \exp\left\{-\frac{1}{2}a(\theta-\frac{b}{a})^2\right\}\\
 &= \exp\left\{-\frac{1}{2}\left(\frac{\theta-\frac{b}{a}}{\frac{1}{\sqrt{a}}}\right)^2\right\}
\end{align*}
$$

以上より$p(\theta\mid y_1, \ldots , y_n,\sigma^2)$は正規分布の密度と同様の形状

この分布の平均と分散をそれぞれ$\mu_n$と$\tau_n^2$とすると、以下のように表せる

$$
\begin{align*}
\mu_n = \frac{b}{a} = \frac{\frac{\mu_0}{\tau_0^2}+\frac{n\bar{y}}{\sigma^2}}{\frac{1}{\tau_0^2}+\frac{n}{\sigma^2}}, \;
\tau_n^2 = \frac{1}{a} = \frac{1}{\frac{1}{\tau_0^2}+\frac{n}{\sigma^2}}
\end{align*}
$$

### 事後分散

$$
\begin{align*}
\frac{1}{\tau_n^2} = a = \frac{1}{\tau_0^2}+\frac{n}{\sigma^2}
\end{align*}
$$

分散の逆数は**精度**と呼ばれる

- $\tilde{\sigma}^2=\frac{1}{\sigma^2}=\;$標本精度
- $\tilde{\tau_0}^2=\frac{1}{\tau_0^2}=\;$事前分布の精度
- $\tilde{\tau_n}^2=\frac{1}{\tau_n^2}=\:$事後分布の精度

⟹ 事後の情報 = 事前の情報 + データの持つ情報

### 事後平均

$$
\begin{align*}
\mu_n = \frac{\tilde{\tau_0}^2}{\tilde{\tau_0}^2+n\tilde{\sigma}^2}\mu_0+\frac{n\tilde{\sigma}^2}{\tilde{\tau_0}^2+n\tilde{\sigma}^2}\bar{y}
\end{align*}
$$

よって事後平均 = 事前平均と標本平均の加重平均

$\tau_0^2=\frac{\sigma^2}{\kappa_0}$と定めた場合は

$$
\begin{align*}
\mu_n = \frac{\kappa_0}{\kappa_0+n}\mu_0+\frac{n}{\kappa_0+n}\bar{y}
\end{align*}
$$

### 新たな観測値の予測

$$
\begin{align*}
\{\tilde{Y}\mid\theta,\sigma^2\}\sim\mathcal{N} ( \theta,\sigma^2 )\;
\Leftrightarrow\;
\tilde{Y}=\theta+\tilde{\epsilon},\;\{\tilde{\epsilon}\mid\theta,\sigma^2\}\sim\mathcal{N} ( \theta,\sigma^2 )
\end{align*}
$$

これを用いて

$$
\begin{align*}
\mathrm{E}[\tilde{Y}\mid y_1, \ldots , y_n,\sigma^2] &= \mathrm{E}[\theta+\tilde{\epsilon}\mid y_1, \ldots , y_n,\sigma^2]\\
&= \mathrm{E}[\theta\mid y_1, \ldots , y_n,\sigma^2]+\mathrm{E}[\tilde{\epsilon}\mid y_1, \ldots , y_n,\sigma^2]\\
&= \mu_n+0=\mu_n\\
\mathrm{Var}[\tilde{Y}\mid y_1, \ldots , y_n,\sigma^2] &= \mathrm{Var}[\theta+\tilde{\epsilon}\mid y_1, \ldots , y_n,\sigma^2]\\
&= \mathrm{Var}[\theta\mid y_1, \ldots , y_n,\sigma^2]+\mathrm{Var}[\tilde{\epsilon}\mid y_1, \ldots , y_n,\sigma^2]\\
&= \tau_n^2+\sigma^2
\end{align*}
$$

よって

$$
\begin{align*}
\tilde{Y}\mid y_1, \ldots , y_n,\sigma^2\sim\mathcal{N} ( \mu_n,\tau_n^2+\sigma^2 )
\end{align*}
$$

## 演習問題 5.5

### (a)

$$
\begin{align*}
\ell(\theta, \psi \mid \mathbf{y}) 
&= \sum_{i=1}^n \log p(y_i \mid \theta, \psi) \\
&= \sum_{i=1}^n \log \left( (2\pi)^{-\frac{1}{2}} \psi^{\frac{1}{2}} \exp \left( -\frac{\psi}{2} (y_i - \theta)^2 \right) \right) \\
&= \sum_{i=1}^n \left\{ \log (2\pi)^{-\frac{1}{2}} + \log \psi^{\frac{1}{2}} - \frac{\psi}{2} (y_i - \theta)^2 \right\} \\
&= -\frac{n}{2} \log (2\pi) + \frac{n}{2} \log \psi - \frac{\psi}{2} \sum_{i=1}^n (y_i - \theta)^2
\end{align*}
$$

### (b)

$$
\begin{align*}
\ell(\theta, \psi \mid \mathbf{y}) 
&= -\frac{n}{2} \log (2\pi) + \frac{n}{2} \log \psi - \frac{\psi}{2} \sum_{i=1}^n (y_i - \theta)^2 \\
&= -\frac{n}{2} \log (2\pi) + \frac{n}{2} \log \psi - \frac{\psi}{2} \left( \sum_{i=1}^n (y_i - \bar{y})^2 + n(\bar{y} - \theta)^2 \right) \\
&= -\frac{n}{2} \log (2\pi) + \frac{n}{2} \log \psi - \frac{\psi}{2} ns^2 - \frac{\psi}{2} n(\bar{y} - \theta)^2
\end{align*}
$$

従って

$$
\begin{align*}
\log p_U(\theta, \psi) &= \frac{\ell(\theta, \psi \mid \mathbf{y})}{n} + c \\
&= -\frac{1}{2} \log (2\pi) + \frac{1}{2} \log \psi - \frac{\psi}{2} s^2 - \frac{\psi}{2} (\bar{y} - \theta)^2 + c
\end{align*}
$$

となるので

$$
\begin{align*}
p_U(\theta, \psi) &= (2\pi)^{-\frac{1}{2}} \psi^{\frac{1}{2}} \exp\left( -\frac{s^2}{2} \psi \right) \exp\left( -\frac{\psi}{2} (\bar{y} - \theta)^2 \right) \exp(c) \\
&\propto \psi^{\frac{1}{2}} \exp\left( -\frac{1}{2} \psi (\theta - \bar{y})^2 \right) \times \psi^{1-1} \exp\left( -\frac{s^2}{2} \psi \right) \\
&\propto \text{dnorm}(\theta, \bar{y}, \psi^{-1}) \times \text{dgamma}(\psi, 1, \frac{s^2}{2})
\end{align*}
$$

### (c)

$$
\begin{align*}
p_U(\theta, \psi \mid \mathbf{y}) 
&\propto p_U(\theta, \psi) \times p(y_1, \ldots, y_n \mid \theta, \psi) \\
&\propto \exp\left( -\frac{\psi}{2}(\theta - \bar{y})^2 \right) 
\times \psi^{\frac{1}{2}} \exp\left( -\frac{s^2}{2} \psi \right) 
\times \psi^{\frac{n}{2}} \exp\left( -\frac{\psi}{2} \sum_{i=1}^n (y_i - \theta)^2 \right) \\
&= \exp\left( -\frac{\psi}{2}(\theta - \bar{y})^2 \right) 
\times \psi^{\frac{1}{2}} \exp\left( -\frac{s^2}{2} \psi \right) 
\times \psi^{\frac{n}{2}}\exp\left( -\frac{\psi}{2} \left( \sum_{i=1}^n (y_i - \bar{y})^2 + n(\bar{y} - \theta)^2 \right) \right) \\
&= \exp\left( -\frac{\psi}{2}(\theta - \bar{y})^2 \right) 
\times \psi^{\frac{n+1}{2}} \exp\left( -\frac{s^2}{2} \psi \right) 
\times \exp\left( -\frac{ns^2}{2} \psi \right) 
\times \exp\left( -\frac{\psi}{2} n(\bar{y} - \theta)^2 \right) \\
&= \exp\left( -\frac{(n+1)\psi}{2}(\theta - \bar{y})^2 \right) 
\times \psi^{\frac{n+1}{2}} \exp\left( -\frac{(n+1)s^2}{2} \psi \right) \\
&\propto \text{dnorm}\left(\theta, \bar{y}, \frac{1}{(n+1)\psi}\right) 
\times \text{dgamma}\left(\psi, \frac{n+3}{2}, \frac{(n+1)s^2}{2} \right)
\end{align*}
$$

上式より、同時密度は確率密度とみなせる