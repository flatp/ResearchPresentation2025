---
layout: page
title: 7月3日
---

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

## 11.4 一般化線形混合効果モデル -後半

$$
\begin{align*}
\beta_1,\ldots,\beta_m &\sim \mathrm{i.i.d.\ multivariate\ normal}(\theta, \Sigma)
\end{align*}
$$

$$
\begin{align*}
\theta &\sim \mathrm{multivariate\ normal}(\mu_0, \Lambda_0)\\
\Sigma &\sim \mathrm{inverse-Wishart}(\eta_0, S_0^{-1})
\end{align*}
$$

事前の明示的なデータがなく、$\mu_0, \Lambda_0, \eta_0, S_0$の適切な値を設定することが難しいため、単位情報事前分布を用いる

1. 各マウスごとに$\{\log(y_{1,j}+\frac{1}{n}),\ldots,\log(y_{n,j}+\frac{1}{n})\}$を$\{x_1,\ldots,x_{20}\}$に回帰することで予備的な推定値$\tilde{\beta}_j$を計算
2. $\theta$の事前分布
    - $\mu_0 = \frac{1}{n}\sum_{j=1}\tilde{\beta}_j$
    - $\Lambda_0$は$\tilde{\beta}_j,\ldots,\tilde{\beta}_j$の標本共分散行列
3. $\Sigma$の事前分布
    - $S_0$は観測値の標本共分散行列
    - $\eta_0=p+2=7$



```R
## データ
library(mvtnorm)
library(monomvn)
XY.tumor <- dget("XY.tumor.txt")
Y <- XY.tumor$Y; X <- XY.tumor$X; m <- dim(Y)[1]; p <- dim(X)[2]

## 事前分布
BETA <- NULL
for (j in 1:m){
  BETA <- rbind(BETA, lm( log(Y[j,] + 1/20) ~ -1 + X[,,j] )$coef)
}

mu0 <- apply(BETA, 2, mean)
S0 <- cov(BETA); eta0 <- p + 2
iL0 <- iSigma <- solve(S0)

## MCMC
THETA.post <- NULL; set.seed(1)
for(s in 1:50000){

  ## theta の更新
  Lm <- solve( iL0 + m * iSigma )
  mum <- Lm %*% ( iL0 %*% mu0 + iSigma %*% apply(BETA, 2, sum) )
  theta <- t( rmvnorm(1, mum, Lm) )

  ## Sigma の更新
  mtheta <- matrix(theta, m, p, byrow=TRUE)
  iSigma <- rwish(eta0 + m, solve(S0 + t(BETA - mtheta) %*% (BETA - mtheta)))

  ## beta の更新
  Sigma <- solve(iSigma)
  for(j in 1:m){
    beta.p <- t( rmvnorm(1, BETA[j,], 0.5 * Sigma) )
    lr <- sum( dpois(Y[j,], exp(X[,,j] %*% beta.p), log=TRUE) -
               dpois(Y[j,], exp(X[,,j] %*% BETA[j,]), log=TRUE) +
               dmvnorm(t(beta.p), theta, Sigma, log=TRUE) -
               dmvnorm(t(BETA[j,]), theta, Sigma, log=TRUE) )
    if( log(runif(1)) < lr ){ BETA[j,] <- beta.p }
  }

  ## アウトプットの保存
  if( s %% 10 == 0 ){ THETA.post <- rbind(THETA.post, t(theta)) }
}
```

![(a)](/image/0703.png)

不確実性の蓄積

1. $\theta$の不確実性
2. マウス間の異質性を考慮した不確実性
3. 観測値の不確実性

## 11.5 補足と文献案内

階層モデルに対するMCMCでは不適切なミキシングが生じる可能性がある
- モデル内に多数存在するパラメータの間では相関が高く、自己相関の高いサンプルパスが生成されてしまう可能性があるため

## 演習問題 11.1

### $\boldsymbol{\theta}, \boldsymbol{\Sigma}$

$$
\begin{align*}
p(\beta_1, \ldots, \beta_m \mid \boldsymbol{\theta}, \boldsymbol{\Sigma})

&\propto |\boldsymbol{\Sigma}|^{-m/2} 
\exp\left\{ -\frac{1}{2} \sum_{i=1}^m (\beta_i - \boldsymbol{\theta})^T \boldsymbol{\Sigma}^{-1} (\beta_i - \boldsymbol{\theta}) \right\}\\

\\

p(\boldsymbol{\theta} \mid \boldsymbol{\Sigma}, \beta_1, \ldots, \beta_m) 
&\propto p(\boldsymbol{\theta}) \times p(\beta_1, \ldots, \beta_m \mid \boldsymbol{\theta}, \boldsymbol{\Sigma})\\

&\propto \exp\left\{ -\frac{1}{2} (\boldsymbol{\theta} - \boldsymbol{\mu}_0)^T \boldsymbol{\Lambda}_0^{-1} (\boldsymbol{\theta} - \boldsymbol{\mu}_0) \right\}

 \times \exp\left\{ -\frac{1}{2} \sum_{i=1}^m (\beta_i^T - \boldsymbol{\theta}^T) \boldsymbol{\Sigma}^{-1} (\beta_i - \boldsymbol{\theta}) \right\}\\

&= \exp\left\{ -\frac{1}{2} (\boldsymbol{\theta}^T \boldsymbol{\Lambda}_0^{-1} - \boldsymbol{\mu}_0^T \boldsymbol{\Lambda}_0^{-1}) (\boldsymbol{\theta} - \boldsymbol{\mu}_0) \right\}

\times \exp\left\{ -\frac{1}{2} \sum_{i=1}^m (\beta_i^T \boldsymbol{\Sigma}^{-1} - \boldsymbol{\theta}^T \boldsymbol{\Sigma}^{-1}) (\beta_i - \boldsymbol{\theta}) \right\}\\

&= \exp\left\{ -\frac{1}{2} \left( \boldsymbol{\theta}^T \boldsymbol{\Lambda}_0^{-1} \boldsymbol{\theta} - 2 \boldsymbol{\mu}_0^T \boldsymbol{\Lambda}_0^{-1} \boldsymbol{\theta} 
+ \boldsymbol{\mu}_0^T \boldsymbol{\Lambda}_0^{-1} \boldsymbol{\mu}_0 \right) \right\}

\times \exp\left\{ -\frac{1}{2} \sum_{i=1}^m \left( \beta_i^T \boldsymbol{\Sigma}^{-1} \beta_i - 2 \boldsymbol{\theta}^T \boldsymbol{\Sigma}^{-1} \beta_i 
+ \boldsymbol{\theta}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{\theta} \right) \right\}\\

&\propto \exp\left\{ -\frac{1}{2} \boldsymbol{\theta}^T (\boldsymbol{\Lambda}_0^{-1}+m\boldsymbol{\Sigma}^{-1}) \boldsymbol{\theta} + \boldsymbol{\theta}^T (\boldsymbol{\Lambda}_0^{-1}\boldsymbol{\mu}_0+m\boldsymbol{\Sigma}^{-1}\bar{\beta})\right\}\\

&\propto \text{multivariate normal}(\boldsymbol{\mu}_m, \boldsymbol{\Lambda}_m), 
\quad \text{where} \quad \boldsymbol{\Lambda}_m = (\boldsymbol{\Lambda}_0^{-1} + m \boldsymbol{\Sigma}^{-1})^{-1}, \quad \boldsymbol{\mu}_m = \boldsymbol{\Lambda}_m(\boldsymbol{\Lambda}_0^{-1}\boldsymbol{\mu}_0 + m \boldsymbol{\Sigma}^{-1}\bar{\beta})\\

\\

p(\boldsymbol{\Sigma} \mid \boldsymbol{\theta}, \beta_1, \ldots, \beta_m) 
&\propto p(\boldsymbol{\Sigma}) \times p(\beta_1, \ldots, \beta_m \mid \boldsymbol{\theta}, \boldsymbol{\Sigma})\\

&\propto |\boldsymbol{\Sigma}|^{-(\eta_0+p+1)/2}\exp\left\{-\frac{1}{2}\mathrm{tr}(S_0 \boldsymbol{\Sigma}^{-1})\right\}

\times |\boldsymbol{\Sigma}|^{-m/2} 
\exp\left\{ -\frac{1}{2} \sum_{i=1}^m (\beta_i - \boldsymbol{\theta})^T \boldsymbol{\Sigma}^{-1} (\beta_i - \boldsymbol{\theta}) \right\}\\

&= |\boldsymbol{\Sigma}|^{-(m+\eta_0+p+1)/2} \exp\left\{ -\frac{1}{2} \text{tr}((S_0+\sum_{i=1}^m(\beta_i-\boldsymbol{\theta})(\beta_i-\boldsymbol{\theta})^T) \boldsymbol{\Sigma}^{-1}) \right\}\\

&\propto \text{inverse Wishart}(\eta_0+m, [S_0+S_{\theta}]^{-1}),\quad \text{where} \quad S_{\theta} = \sum_{i=1}^m(\beta_i-\boldsymbol{\theta})(\beta_i-\boldsymbol{\theta})^T\\
\end{align*}
$$

### $\sigma^2$

$$
\begin{align*}
p(\sigma^2\mid\mathrm{SSR})
&\propto [\gamma^{\frac{\nu_0}{2}-1}\exp(-\gamma\times\frac{\nu_0\sigma_0^2}{2})]
\times [\prod\gamma^{\frac{n_j}{2}}\exp(-\gamma\times\frac{\mathrm{SSR}}{2})],
\quad \text{where}\quad \gamma=\frac{1}{\sigma^2}\\
&= \gamma^{\frac{\nu_0+\sum n_j}{2}-1}\exp(-\gamma\times\frac{\nu_0\sigma_0^2+\mathrm{SSR}}{2})\\
&\propto \mathrm{inverse-Wishart}(\frac{\nu_0+\sum n_j}{2},\frac{\nu_0\sigma_0^2+\mathrm{SSR}}{2}),
\quad \text{where}\quad \mathrm{SSR}=\sum_{J=1}^m\sum_{i=1}^{n_j}(y_{i,j}-\beta_j^Tx_{i,j})^2
\end{align*}
$$

### $\beta_j$

$$
\begin{align*}
p(\beta_j\mid y_j,X_j,\sigma^2,\boldsymbol{\theta},\boldsymbol{\Sigma})
&\propto p(\beta_j) \times p(y_j\mid\beta_j,X_j,\sigma^2,\boldsymbol{\theta},\boldsymbol{\Sigma})\\
&\propto \exp\left\{ -\frac{1}{2} \boldsymbol{\beta_j}^T (\boldsymbol{\Sigma}^{-1}+\mathbf{X}_j^T \mathbf{X}_j) \boldsymbol{\beta_j} + \boldsymbol{\beta_j}^T (\boldsymbol{\Sigma}^{-1} \boldsymbol{\theta} + \mathbf{X}_j^T \mathbf{y}_j / \sigma^2)\right\}\\
\mathrm{Var}[\boldsymbol{\beta_j} \mid \mathbf{y}_j, \mathbf{X}_j, \sigma^2] 
&= \left( \boldsymbol{\Sigma}_0^{-1} + \mathbf{X}_j^T \mathbf{X}_j / \sigma^2 \right)^{-1}\\
\mathrm{E}[\boldsymbol{\beta_j} \mid \mathbf{y}_j, \mathbf{X}_j, \sigma^2] 
&= \left( \boldsymbol{\Sigma}^{-1} + \mathbf{X}_j^T \mathbf{X}_j / \sigma^2 \right)^{-1}
    \left( \boldsymbol{\Sigma}^{-1} \boldsymbol{\theta} + \mathbf{X}_j^T \mathbf{y}_j / \sigma^2 \right)
\end{align*}

$$